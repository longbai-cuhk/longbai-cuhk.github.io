<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Long Bai, Bai Long, EE, Electronic Engineering, CUHK, The Chinese University of Hong Kong, Hongliang Ren"> 
<meta name="description" content="Long Bai&#39;s home page">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<link rel="shortcut icon" href="./pic/mixian.jpeg" type="image/x-icon">
<title>Long Bai's&#39;s Homepage</title>
  
<style>
    @font-face {
      font-family: 'Chinese_handwriting';
      src: url('files/font_Chinese.ttf');
    }

    .chinese-name {
      font-family: 'Chinese_handwriting';
      color: black;
    }
</style>
	
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
</head>
<body>
<div id="layout-content" style="margin-top:25px">



<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Long Bai</h1>
					<h1><span style="font-family: 'Chinese_handwriting';">白龙</span></h1>
				</h1></div>

				<h3>Algorithm Expert (Incoming)</h3>
				<p>
					Alibaba DAMO Academy <br>
					
					<!--<p style="color:#FF0000";> I will graduate in mid-2025 and am looking for an industrial position!</p>-->
					<br>
					
					<!-- Office: UG Building 501 Room 1.01.2, Ismaningerstraße 22, 81675 Munich & <be> -->
					<!-- Room 424, Ho Sin-Hang Engineering Building, CUHK, Shatin, N.T., Hong Kong <br> -->
					Email: b.long AT ieee.org <br>
				
				</p>
				<p> 	<a href="https://scholar.google.com/citations?user=v-fw-98AAAAJ&hl=en"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/longbai1006"><img src="./pic/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://orcid.org/0000-0002-9762-6821"><img src="./pic/orcid.jpeg" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://www.researchgate.net/profile/Long-Bai-13"><img src="./pic/rg.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://www.linkedin.com/in/long-bai-0a37b71a5/"><img src="./pic/LinkedIn_s.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="./pic/WeChat_Long.jpeg"><img src="./pic/wechat.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://wa.me/85259607217/"><img src="./pic/whatsapp.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="mailto:b.long@link.cuhk.edu.hk"><img src="./pic/email.jpeg" height="30px" style="margin-bottom:-3px"></a>
					<!--
					<a href="https://twitter.com/longbaijerry"><img src="./pic/twitter.png" height="30px" style="margin-bottom:-3px"></a>					
					<a href="https://zh-cn.facebook.com/people/Lequan-Yu/100003696557697"><img src="./pic/Facebook_s.png" height="30px" style="margin-bottom:-3px"></a>
					-->
				</p>
			</td>
			<td>
				<img src="./pic/Long.jpg" border="0" width="200"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>
<!--
[<a href="./pic/CV-English-BaiLong.pdf">CV</a>]|[<a href="./pic/CV-Chinese-BaiLong.pdf">简历</a>]
-->
<h2>Biography </h2>
<p>
	I am an incoming Algorithm Expert (Senior Research Scientist) at the <a href="https://damo.alibaba.com/?language=en">Alibaba DAMO Academy</a>. I received my Ph.D. degree in Electronic Engineering at <a href="https://www.cuhk.edu.hk/english/index.html">The Chinese University of Hong Kong (CUHK)</a> in 2025, advised by <a href="https://www.ee.cuhk.edu.hk/en-gb/people/academic-staff/professors/prof-ren-hongliang" target="_blank">Prof. Hongliang Ren</a> and <a href="https://www.ee.cuhk.edu.hk/en-gb/people/academic-staff/professors/prof-lai-jiewen" target="_blank">Prof. Jiewen Lai</a>, with thesis committee members <a href="https://www.ee.cuhk.edu.hk/en-gb/people/academic-staff/professors/prof-tan-lee" target="_blank">Prof. Tan Lee</a>, <a href="https://www.cse.cuhk.edu.hk/people/faculty/qi-dou/" target="_blank">Prof. Qi Dou</a>, and <a href="https://www.linkedin.com/in/s-kevin-zhou-231a094b/" target="_blank">Prof. Kevin S. Zhou</a>. During my Ph.D. study, I was a visiting student at <a href="https://www.tum.de/" target="_blank">Technical University of Munich (TUM)</a>, advised by <a href="https://www.cs.cit.tum.de/camp/members/cv-nassir-navab/nassir-navab/" target="_blank">Prof. Nassir Navab</a>; and at <a href="https://www.sydney.edu.au/" target="_blank">The University of Sydney (USYD)</a>, advised by <a href="https://sites.google.com/view/lupingzhou" target="_blank">Prof. Luping Zhou</a>. Previously, I received the B. Sc. degree in Opto-Electronics Information Science and Engineering from <a href="https://english.bit.edu.cn/">Beijing Institute of Technology (BIT)</a> in 2021, advised by <a href="https://opt.bit.edu.cn/jsdw/jsml/gdcxyxxgcyjs/c748795cd272417f9e5733a068db1962.htm" target="_blank">Prof. Kun Gao</a>. I am fortunate to have been working with <a href="https://mobarakol.github.io/" target="_blank">Prof. Mobarak I. Hoque</a> (UoM), <a href="https://www.cs.cit.tum.de/camp/members/zhongliang-jiang/" target="_blank">Dr. Zhongliang Jiang</a> (TUM), and <a href="https://scholar.google.com/citations?user=OJUbSAMAAAAJ&hl=en" target="_blank">Yanheng Li</a> (CityU HK).
	<!--Previously, I received the B. Sc. degree from Opto-Electronics Information Science and Engineering at <a href="https://english.bit.edu.cn/">Beijing Institute of Technology</a> in 2021.</p>--> 
</p>

<p>
	My research interests include artificial intelligence and its applications in medical image computing, human-robot interaction, and surgical data science. I recently work on vision-language understanding and generation.
</p>
<!--<p>My research interests include medical image computing, robotic video perception, and artificial intelligence. Specifically, I am dedicated to developing learning algorithms for complex time-series medical data analysis, applied primarily to endoscopy and robotic surgery. I recently work on data efficient learning to minimize human annotation.</p>-->

<!--<p>
	I will join the Medical AI Lab, <a href="https://damo.alibaba.com/?language=en"><b>Alibaba DAMO Academy</b></a> <b> in Aug 2025 </b> as an algorithm expert under the leadership of <a href="https://lelu007.github.io/">Dr. Le Lu</a>.
</p>-->

<!--<p style="color:red;"> <b>*Opening!*</b> XXX </p>-->

<!-- <p>If you are interested in joining <a href="http://www.labren.org/mm/">Ren Lab</a> as a research intern, feel free to drop me an email! CUHK undergraduate/MSc students may check our <a href="https://www.osa.cuhk.edu.hk/flourishingcuhk/student-helper-engagement-scheme/for-students/">Student Helper</a> programme. Collaboration is also welcome!</p> -->

<!--<p style="color:red;">
	<a href="https://www.ucl.ac.uk/surgical-robot-vision/"> SRV group, WEISS</a> is looking for self-motivated summer interns (2022), to work on the research areas of robotic surgery intelligence and surgical 3D vision. Welcome to drop me an email with your CV. Remote collaboration is also welcome.
</p>-->

<h2>News</h2>
<div style="height: 280px; overflow: auto;">
<ul>	
	<li>
		[07/2025] I will attend <a href="http://mics2025.com/">MICS 2025</a> during July 19-20 in Cixi, China.
	</li>
	<li>
		[07/2025] Serve as an Invited Lecturer at <a href="https://www.edu4sds.org/#">Surgical Data Science (SDS) Summer School</a> 2025 in Strasbourg, France.
	</li>
	<li>
		[06/2025] One paper  <a href="https://www.sciencedirect.com/science/article/pii/S0895611125001004">PedSemiSeg</a> is accepted by <a href="https://www.sciencedirect.com/journal/computerized-medical-imaging-and-graphics" target="_blank">Computerized Medical Imaging and Graphics</a> (IF: 4.9).
	</li>
	<li>
		[06/2025] Four papers <a href="https://arxiv.org/abs/2412.14018">SurgSora</a>, <a href="https://arxiv.org/abs/2506.23308">Endo-4DGX</a>, <a href="https://arxiv.org/abs/2506.23309">SurgTPGS</a>, and <a href="https://arxiv.org/abs/2506.20254">SPA</a> are accepted by <a href="https://conferences.miccai.org/2025/en/" target="_blank">MICCAI 2025</a>.
	</li>
	<li>
		[06/2025] One paper  <a href="https://www.arxiv.org/abs/2506.16263">CapsDT</a> is accepted by <a href="https://www.iros25.org/" target="_blank">IROS 2025</a> as <b>Oral</b> Presentation.
	</li>
	<li>
		[06/2025] One paper  <a href="https://www.arxiv.org/abs/2506.06830" target="_blank">EndoARSS</a> is accepted by <a href="https://advanced.onlinelibrary.wiley.com/journal/26404567" target="_blank">Advanced Intelligent Systems</a> (IF: 6.1).
	</li>
	<li>
		[06/2025] Successfully passed my Ph.D. Thesis Defense and became a Dr. now!
	</li>
	<li>
		[05/2025] A co-author paper <a href="https://arxiv.org/abs/2411.18884" target="_blank">ETSM</a> won the Best Application Award at the poster presentation of <a href="https://www.mrc-cuhk-symposium.org/" target="_blank">MRC Symposium 2025</a>!
	</li>
	<li>
		[05/2025] I will attend <a href="https://www.mrc-cuhk-symposium.org/" target="_blank">MRC Symposium 2025</a> during May 29-31 in Hong Kong SAR, China.
	</li>
	<li>
		[05/2025] <a href="https://sites.google.com/view/iros-2025-c4sr/home" target="_blank">The 3rd C4SR+ Workshop</a> is accepted by <a href="https://www.iros25.org/" target="_blank">IROS 2025</a>, and welcome to join us in Hangzhou, China!
	</li>
	<li>
		[05/2025] One paper  <a href="http://arxiv.org/abs/2505.01766" target="_blank">GRAD</a> is accepted by <a href="https://www.sciencedirect.com/journal/information-fusion" target="_blank">Information Fusion</a> (IF: 15.5).
	</li>
	<li>
		[03/2025] Check our recent technical report of <a href="https://arxiv.org/abs/2503.23130" target="_blank">DeepSeek in Robotic Surgery</a>.
	</li>
	<li>
		[02/2025] We will host <a href="https://sites.google.com/view/ema4miccai2025/home" target="_blank">The 1st Workshop on Efficient Medical AI</a> in MICCAI 2025 and see you in Daejeon, Korea!
	</li>
	<li>
		[01/2025] Three papers <a href="https://arxiv.org/abs/2501.19319" target="_blank">Endo-2DTAM</a>, <a href="https://arxiv.org/abs/2409.12467" target="_blank">SurgPLAN++</a>, and <a href="https://arxiv.org/abs/2411.18884" target="_blank">ETSM</a> are accepted by <a href="https://2025.ieee-icra.org/" target="_blank">ICRA 2025</a>.
	</li>
	<li>
		[01/2025] One paper <a href="https://openreview.net/forum?id=ZsU52Zkzjr" target="_blank">PvNeXt</a> is accepted by <a href="https://iclr.cc/Conferences/2025" target="_blank">ICLR 2025</a>.
	</li>
	<li>
		[01/2025] The preprint of our recent work <a href="http://arxiv.org/abs/2501.11347" target="_blank">EndoChat</a> on MLLM for endoscopic surgery is online!
	</li>
	<li>
		[12/2024] One paper <a href="http://arxiv.org/abs/2412.17595" target="_blank">V<sup>2</sup>-SfMLearner</a> is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8856" target="_blank">IEEE Transactions on Automation Science and Engineering</a> (IF: 6.4).
	</li>
	<li>
		[12/2024] Check our recent work <a href="https://surgsora.github.io/" target="_blank">SurgSora</a> on controllable surgical video generation!
	</li>
	<li>
		[10/2024] Moved to Munich, Germany, and joined <a href="https://www.cs.cit.tum.de/camp/start/" target="_blank">CAMP</a>, <a href="https://www.tum.de/" target="_blank">Technical University of Munich (TUM)</a>!
	</li>
	<li>
		[10/2024] <a href="https://arxiv.org/abs/2405.10550" target="_blank">LighTDiff</a> won the <b>MICCAI 2024 Best Paper Runner Up (3/2771)</b>!
	</li>
	<li>
		[10/2024] Two papers are accepted by <a href="https://ieee-robio.org/2024/" target="_blank">IEEE ROBIO 2024</a>.
	</li>
	<li>
		[10/2024] Our team won the <b>runner-up</b> of MICCAI 2024 <a href="https://www.synapse.org/Synapse:syn53708249/wiki/627501" target="_blank">BraTS Challenge on Sub-Sahara-Africa Adult Glioma</a>.
	</li>
	<li>
		[09/2024] Our paper <a href="https://arxiv.org/abs/2405.10550" target="_blank">LighTDiff</a> is selected in <b>MICCAI 2024 Best Paper and Young Scientist Award Shortlist</b>.
	</li>
	<li>
		[07/2024] One paper <a href="https://arxiv.org/abs/2408.04958" target="_blank">Surgical-VQLA++</a> is accepted by <a href="https://www.sciencedirect.com/journal/information-fusion" target="_blank">Information Fusion</a> (IF: 15.5).
	</li>
	<li>
		[07/2024] I am awarded the <b>CUHK PhD IMPAC Award</b>.
	</li>
	<li>
		[06/2024] One paper <a href="https://arxiv.org/abs/2407.19435" target="_blank">ASI-Seg</a> is accepted by <a href="https://iros2024-abudhabi.org/" target="_blank">IROS 2024</a> as <b>Oral</b> Presentation.
	</li>
	<li>
		[06/2024] Our <a href="http://arxiv.org/abs/2401.06013" target="_blank">Surgical-DINO</a> is selected as <b>Long Oral</b> and receives the <b>IPCAI 2024 Best Paper Award Shortlist</b>!
	</li>
	<li>
		[06/2024] Four papers are accepted by <a href="https://conferences.miccai.org/2024/en/" target="_blank">MICCAI 2024</a> (with <b>2 early accepted</b> & <b>1 oral</b>)!
	</li>
	<li>
		[05/2024] I am awarded the <b>CUHK Overseas Research Attachment Scholarship</b> 2024-2025.
	</li>
	<li>
		[05/2024] Our poster on surgical instrument tracking receives the <b>Best Poster Award</b> in <a href="https://sites.google.com/view/icra24-c4sr" target="_blank">ICRA 2024 C4SR+ Workshop</a>!
	</li>
	<li>
		[02/2024] One paper <a href="https://arxiv.org/abs/2402.05860" target="_blank">CAT-SD</a> is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=42" target="_blank">IEEE TMI</a> (IF: 9.8).
	</li>
	<li>
		[02/2024] One paper <a href="https://arxiv.org/abs/2402.11476" target="_blank">EndoOOD</a> is accepted by <a href="https://biomedicalimaging.org/2024/" target="_blank">IEEE ISBI 2024</a>.
	</li>
	<li>
		[01/2024] One paper <a href="http://arxiv.org/abs/2402.06985" target="_blank">OSSAR</a> is accepted by <a href="https://2024.ieee-icra.org/" target="_blank">ICRA 2024</a> with the <b>IEEE RAS Travel Grant Award</b>.
	</li>
	<li>
		[01/2024] One paper on AI-assisted needle insertion simulator is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7361" target="_blank">IEEE Sensors Journal</a>.
	</li>
	<li>
		[12/2023] One paper <a href="http://arxiv.org/abs/2401.06013" target="_blank">Surgical-DINO</a> is <b>early accepted</b> by <a href="https://sites.google.com/view/ipcai2024/home" target="_blank">IPCAI 2024</a>.
	</li>
	<li>
		[12/2023] One paper on style transfer for VR is accepted by <a href="https://2024.hci.international" target="_blank">HCII 2024</a>.
	</li>
	<li>
		[10/2023] One paper on multimodal image fusion is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7361" target="_blank">IEEE Sensors Journal</a>.
	</li>
	<li>
		[09/2023] One paper on pain communication is accepted by <a href="https://www.frontiersin.org/journals/physiology" target="_blank">Frontiers in Physiology</a>.
	</li>
	<li>
		[08/2023] One paper <a href="https://arxiv.org/abs/2308.14100" target="_blank">EndoCSS</a> is accepted by <a href="https://www.sciencedirect.com/journal/computers-in-biology-and-medicine" target="_blank">Computers in Biology and Medicine</a>.
	</li>
	<li>
		[07/2023] One paper <a href="https://arxiv.org/abs/2309.10431" target="_blank">AdaptPoint</a> is accepted by <a href="https://iccv2023.thecvf.com/" target="_blank">ICCV 2023</a>.
	</li>
	<li>
		[07/2023] I passed my Ph.D. proposal defense and became a Ph.D. candidate! 
	</li>
	<li>
		[07/2023] Our paper on intubation landmark detection receives the <b>ICBIR 2023 Best Student Paper Award</b>!
	</li>
	<li>
		[07/2023] Two papers are accepted by <a href="http://www.icbir.org/" target="_blank">ICBIR 2023</a>.
	</li>
	<li>
		[06/2023] One paper on CT airway extraction is accepted by <a href="https://www.sciencedirect.com/journal/artificial-intelligence-in-medicine" target="_blank">Artificial Intelligence in Medicine</a>. 
	</li>
	<li>
		[06/2023] One paper on pulmonary vessel segmentation is accepted by <a href="https://www.springer.com/journal/11517" target="_blank">MBEC</a> Journal.
	</li>
	<li>
		[06/2023] One paper on oropharyngeal organ sim-to-real segmentation is accepted by <a href="https://www.springer.com/journal/11517" target="_blank">MBEC</a> Journal.
	</li>
	<li>
		[06/2023] Three papers <a href="https://arxiv.org/abs/2307.02452" target="_blank">LLCaps</a>, <a href="https://arxiv.org/abs/2307.05182" target="_blank">CAT-ViL</a> and <a href="https://arxiv.org/abs/2307.12045" target="_blank">CS-VQLA</a> are accepted by <a href="https://conferences.miccai.org/2023/en/" target="_blank">MICCAI 2023</a> (1 <b>oral</b> & 2 <b>posters</b>).
	</li>
	<li>
		[06/2023] One paper on deep learning-assisted micro force sensing is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19" target="_blank">IEEE TIM</a>.
	</li>
	<li>
		[06/2023] Our poster on sim-to-real receives the <b>Best Poster Award</b> in <a href="https://sites.google.com/view/icra2023workshop-surgicalrobot/" target="_blank">ICRA 2023 Workshop on Surgical Robotics</a>!
	</li>
	<li>
		[01/2023] One paper <a href="https://ieeexplore.ieee.org/document/10160403" target="_blank">Surgical-VQLA</a> is accepted by <a href="https://www.icra2023.org/" target="_blank">ICRA 2023</a> with the <b>IEEE RAS Travel Grant Award</b>.
	</li>
	<li>
		[01/2023] One poster is accepted by <a href="https://ieeevr.org/2023/" target="_blank">IEEE VR 2023</a>.
	</li>
	<li>
		[10/2022] One paper on reinforcement learning and stomach coverage of WCE is accepted by <a href="https://irmv.sjtu.edu.cn/robio2022/" target="_blank">ROBIO 2022</a>.
	</li>
</ul>
</div>


<h2>Selected Awards</h2>
<table style="border-spacing:2px">
		<body>
		<tr><td> 2025, MRC Symposium Best Application Award</td></tr>
		<tr><td> 2024, MICCAI Best Paper Runner Up (3/2771)</td></tr>
		<tr><td> 2024, Runner Up of MICCAI BraTS Challenge on Sub-Sahara-Africa Adult Glioma</td></tr>
		<tr><td> 2024, PhD International Mobility for Partnerships and Collaborations (IMPAC) Award</td></tr>
		<tr><td> 2024, IPCAI Best Paper Award Shortlist</td></tr>
		<tr><td> 2024, CUHK Overseas Research Attachment Scholarship</td></tr>
		<tr><td> 2024, Best Poster Award of ICRA 2024 C4SR+ Workshop</td></tr>
		<tr><td> 2024, IEEE ICRA RAS Travel Grants Award</td></tr>
		<tr><td> 2023, ICBIR Best Student Paper Award</td></tr>
		<tr><td> 2023, Best Poster Award of IEEE ICRA Workshop on Surgical Robotics</td></tr>
		<tr><td> 2023, IEEE ICRA RAS Travel Grants Award</td></tr>
		<tr><td> 2021, Merit Award of EMedIC Global</td></tr>
		<tr><td> 2021-2025, CUHK Vice-Chancellor's Ph.D. Scholarship Scheme</td></tr>
    	<!--<tr><td> BIT Academic Excellent Scholarship, 2020</td></tr>
    	<tr><td> BIT Academic Progress Scholarship, 2019</td></tr>-->
	</tbody>
</table>

<h2>Publications [Full list at <a href="https://scholar.google.com/citations?user=v-fw-98AAAAJ&hl=en">Google Scholar</a>]</h2>
	<!-- <p><font face="Arial" size="4"><b>2023</b></font></p> -->
* indicates equal contribution; † indicates project lead/corresponding author.
<!-- <h3><font face="Arial"> Preprints</h3> -->
<h3>Preprints</h3>
	<ul>

		<li>
			<a href="http://arxiv.org/abs/2505.15206" target="_blank">EndoVLA: Dual-Phase Vision-Language-Action Model for Autonomous Tracking in Endoscopy</a><br>
			Chi Kit Ng*, <b>Long Bai*</b>, Guankun Wang*, Yupeng Wang, Huxin Gao, Kun Yuan, Chenhan Jin, Tieyong Zeng, Hongliang Ren <br>
			<em>Preprint</em>, 2025. <br>
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2503.23130" target="_blank">Can DeepSeek Reason Like a Surgeon? An Empirical Evaluation for Vision-Language Understanding in Robotic-Assisted Surgery</a><br>
			Boyi Ma, Yanguang Zhao, Jie Wang, Guankun Wang, Kun Yuan, Tong Chen, <b>Long Bai†</b>, Hongliang Ren <br>
			<em>Preprint</em>, 2025. <br>
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2503.15917" target="_blank">Learning to Efficiently Adapt Foundation Models for Self-Supervised Endoscopic 3D Scene Reconstruction from Any Cameras</a><br>
			Beilei Cui*, <b>Long Bai*</b>, Mobarakol Islam*, An Wang, Zhiqi Ma, Yiming Huang, Feng Li, Zhen Chen, Zhongliang Jiang, Nassir Navab, Hongliang Ren <br>
			<em>Preprint</em>, 2025. <br>
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="http://arxiv.org/abs/2501.11347" target="_blank">EndoChat: Grounded Multimodal Large Language Model for Endoscopic Surgery</a><br>
			Guankun Wang*,  <b>Long Bai*</b>, Junyi Wang*, Kun Yuan*, Zhen Li, Tianxu Jiang, Xiting He, Jinlin Wu, Zhen Chen, Zhen Lei, Hongbin Liu, Jiazheng Wang, Fan Zhang, Nicolas Padoy, Nassir Navab, Hongliang Ren <br>
			<em>Preprint</em>, 2024. <br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/gkw0010/EndoChat" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2408.04593" target="_blank">SAM 2 in Robotic Surgery: An Empirical Evaluation for Robustness and Generalization in Surgical Video Segmentation</a><br>
			Jieming Yu, An Wang, Wenzhen Dong, Mengya Xu, Mobarakol Islam, Jie Wang, <b>Long Bai†</b>, Hongliang Ren <br>
			<em>Preprint</em>, 2024. <br>
		</li>
			<p style="margin-top:3px">

			</p>
		
	</ul>

<h3>Book Chapters</h3>
	<ul>

		<li>
			<a href="https://www.sciencedirect.com/science/article/abs/pii/B9780443132711000078" target="_blank">Ultrasound Guidance and Robotic Procedures: Actual and Future Intelligence</a><br>
			<b>Long Bai*</b>, Lei Zhao*, Hongliang Ren <br>
			<em>Handbook of Robotic Surgery</em>, 2024. <br>
		</li>
			<p style="margin-top:3px">

			</p>
		

		<li>
			<a href="https://www.sciencedirect.com/science/article/abs/pii/B9780443132711000571" target="_blank">3D Reconstruction of Deformable Tissues in Robotic Surgery</a><br>
			Mengya Xu, Tiebing Tang, Ziqi Guo, An Wang, Beilei Cui, <b>Long Bai</b>, Hongliang Ren <br>
			<em>Handbook of Robotic Surgery</em>, 2024. <br>
		</li>
			<p style="margin-top:3px">

			</p>
	</ul>
	
<h3>Journal Papers</h3>
	<ul>
		
		<li>
			<a href="https://www.sciencedirect.com/science/article/pii/S0895611125001004" target="_blank">PedSemiSeg: Pedagogy-inspired Semi-supervised Polyp Segmentation</a><br>
			An Wang, Haoyu Ma, <b>Long Bai</b>, Yanan Wu, Mengya Xu, Yang Zhang, Mobarakol Islam, Hongliang Ren <br>
			<em>Computerized Medical Imaging and Graphics</em>, 2025. (IF: 4.9) <br> 
		</li>
			<p style="margin-top:3px">
				
			</p>
		
		<li>
			<a href="https://www.arxiv.org/abs/2506.06830" target="_blank">EndoARSS: Adapting Spatially-Aware Foundation Model for Efficient Activity Recognition and Semantic Segmentation in Endoscopic Surgery</a><br>
			Guankun Wang, Rui Tang, Mengya Xu, <b>Long Bai</b>, Huxin Gao, Hongliang Ren <br>
			<em>Advanced Intelligent Systems</em>, 2025. (IF: 6.1) <br> 
		</li>
			<p style="margin-top:3px">
				
			</p>
		
		<li>
			<a href="http://arxiv.org/abs/2505.01766" target="_blank">Multimodal Graph Representation Learning for Robust Surgical Workflow Recognition with Adversarial Feature Disentanglement</a><br>
			<b>Long Bai*</b>, Boyi Ma*, Ruohan Wang, Guankun Wang, Beilei Cui, Zhongliang Jiang, Mobarakol Islam, Zhe Min, Jiewen Lai, Nassir Navab, Hongliang Ren <br>
			<em>Information Fusion</em>, 2025. (IF: 15.5) <br> 
		</li>
			<p style="margin-top:3px">
				
			</p>
		
		<li>
			<a href="http://arxiv.org/abs/2412.17595" target="_blank">V<sup>2</sup>-SfMLearner: Learning Monocular Depth and Ego-motion for Multimodal Wireless Capsule Endoscopy</a><br>
			<b>Long Bai*</b>, Beilei Cui*, Liangyu Wang*, Yanheng Li, Shilong Yao, Sishen Yuan, Yanan Wu, Yang Zhang, Max Q.-H. Meng, Zhen Li, Weiping Ding, Hongliang Ren <br>
			<em>IEEE Transactions on Automation Science and Engineering</em> (<i><b>TASE</b></i>), 2025. (IF: 6.4) <br> 
		</li>
			<p style="margin-top:3px">
				
			</p>

		<li>
			<a href="https://arxiv.org/abs/2408.04958" target="_blank">Surgical-VQLA++: Adversarial Contrastive Learning for Calibrated Robust Visual Question-Localized Answering in Robotic Surgery</a><br>
			<b>Long Bai*</b>, Guankun Wang*, Mobarakol Islam*, Lalithkumar Seenivasan, An Wang, Hongliang Ren <br>
			<em>Information Fusion</em>, 2025. (IF: 15.5) <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/Surgical-VQLAPlus" target="_blank">Code & Data</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2402.05860" target="_blank">Privacy-Preserving Synthetic Continual Semantic Segmentation for Robotic Surgery</a><br>
			Mengya Xu*, Mobarakol Islam*, <b>Long Bai</b>, Hongliang Ren <br>
			<em>IEEE Transactions on Medical Imaging</em> (<i><b>TMI</b></i>), 2024. (IF: 9.8) <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/XuMengyaAmy/Synthetic_CAT_SD" target="_blank">Code</a>]
			</p>

		<li>
			<a href="http://arxiv.org/abs/2401.06013" target="_blank">Surgical-DINO: Adapter Learning of Foundation Models for Depth Estimation in Endoscopic Surgery</a><br>
			Beilei Cui*, Mobarakol Islam*, <b>Long Bai</b>, Hongliang Ren <br>
			<em>International Journal of Computer Assisted Radiology and Surgery</em> (<i><b>IJCARS, Presented at IPCAI</b></i>), 2024. (IF: 2.3) <br>
			<font color="red">(IPCAI Best Paper Award Shortlist, Long Oral)</font></br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/BeileiCui/SurgicalDINO" target="_blank">Code</a>]
			</p>

		
		<li>
			<a href="https://ieeexplore.ieee.org/abstract/document/10413282/" target="_blank">Data-driven 3D Tactile Cues with Intermediate Soft Interfaces towards Training Needle Insertions</a><br>
			Ruijie Tang*, Shilong Yao*, <b>Long Bai</b>, Hong Yan, Max Q.-H. Meng, Hongliang Ren <br>
			<em>IEEE Sensors Journal</em>, 2024. (IF: 4.5) <br> 
		</li>
			<p style="margin-top:3px">

			</p>
	
		<li>
			<a href="https://arxiv.org/abs/2308.14100" target="_blank">Rethinking Exemplars for Continual Semantic Segmentation in Endoscopy Scenes: Entropy-based Mini-Batch Pseudo-Replay</a><br>
			Guankun Wang*, <b>Long Bai*</b>, Yanan Wu, Tong Chen, Hongliang Ren <br>
			<em>Computers in Biology and Medicine</em> (<i><b>CBM</b></i>), 2023. (IF: 7.0) <br> 
		</li>
			<p style="margin-top:3px">

			</p>

		<li>
			<a href="https://arxiv.org/abs/2310.09937" target="_blank">Joint Sparse Representations and Coupled Dictionary Learning in Multi-Source Heterogeneous Image Pseudo-color Fusion</a><br>
			<b>Long Bai</b>, Shilong Yao, Kun Gao, Yanjun Huang, Ruijie Tang, Hong Yan, Max Q.-H. Meng, Hongliang Ren <br>
			<em>IEEE Sensors Journal</em>, 2023. (IF: 4.3) <br> 
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://www.sciencedirect.com/science/article/abs/pii/S0933365723001513" target="_blank">Two-stage Contextual Transformer-based Convolutional Neural Network for Airway Extraction from CT Images</a><br>
			Yanan Wu, Shuiqing Zhao, Shouliang Qi, Jie Feng, Haowen Pang, Runsheng Chang, <b>Long Bai</b>, Mengqi Li, Shuyue Xia, Wei Qian, Hongliang Ren <br>
			<em>Artificial Intelligence in Medicine</em> (<i><b>AIM</b></i>), 2023. (IF: 6.1) <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/zhaozsq/airway_segmentation" target="_blank">Code</a>]
			</p>

		<li>
			<a href="https://ieeexplore.ieee.org/abstract/document/10159526" target="_blank">An RNN-LSTM Enhanced Compact and Affordable Micro Force Sensing System for Interventional Continuum Robots with Interchangeable End-Effector Instruments</a><br>
			Shilong Yao*, Ruijie Tang*, <b>Long Bai</b>, Hong Yan, Hongliang Ren, Li Liu <br>
			<em>IEEE Transactions on Instrumentation and Measurement</em>, 2023. (IF: 5.6) <br> 
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2305.10883" target="_blank">Domain Adaptive Sim-to-Real Segmentation of Oropharyngeal Organs</a><br>
			Guankun Wang, Tian-Ao Ren, Jiewen Lai, <b>Long Bai</b>, Hongliang Ren <br>
			<em>Medical & Biological Engineering & Computing</em> (<i><b>MBEC</b></i>), 2023. <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/gkw0010/EISOST-Sim2Real-Dataset-Release" target="_blank">Dataset</a>]
			</p>

		<li>
			<a href="https://link.springer.com/article/10.1007/s11517-023-02872-5" target="_blank">Transformer-based 3D U-Net for Pulmonary Vessel Segmentation and Artery-vein Separation from CT Images</a><br>
			Yanan Wu, Shouliang Qi, Meihuan Wang, Shuiqing Zhao, Haowen Pang, Jiaxuan Xu, <b>Long Bai</b>, Hongliang Ren <br>
			<em>Medical & Biological Engineering & Computing</em> (<i><b>MBEC</b></i>), 2023. <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/wuyanan513/Pulmonary-Vessel-Segmentation-and-Artery-vein-Separation" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://www.frontiersin.org/journals/physiology/articles/10.3389/fphys.2023.1248893/full" target="_blank">Rethinking Pain Communication of Patients with Alzheimer's Disease through E-textile Interaction Design</a><br>
			Yanheng Li*, <b>Long Bai*</b>, Yaxuan Mao, Hongliang Ren, Yu Qiao, Xin Tong, Ray LC <br>
			<em>Frontiers in Physiology</em>, 2023. <br> 
		</li>
			<p style="margin-top:3px">

			</p>
	</ul>
	
<h3>Conference Papers</h3>
	<ul>
		<li>
			<a href="https://arxiv.org/abs/2412.14018" target="_blank">SurgSora: Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation</a><br>
			Tong Chen, Shuya Yang, Junyi Wang, <b>Long Bai†</b>, Hongliang Ren, Luping Zhou† <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2025. <br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://surgsora.github.io/" target="_blank">Page</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2506.23308" target="_blank">Endo-4DGX: Robust Endoscopic Scene Reconstruction and Illumination Correction with Gaussian Splatting</a><br>
			Yiming Huang*, <b>Long Bai*</b>, Beilei Cui*, Yanheng Li, Tong Chen, Jie Wang, Jinlin Wu, Zhen Lei, Hongbin Liu, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2025. <br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://lastbasket.github.io/MICCAI-2025-Endo-4DGX/" target="_blank">Page</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2506.23309" target="_blank">SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting</a><br>
			Yiming Huang*, <b>Long Bai*</b>, Beilei Cui*, Kun Yuan, Guankun Wang, Mobarak I. Hoque, Nicolas Padoy, Nassir Navab, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2025. <br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://lastbasket.github.io/MICCAI-2025-SurgTPGS/" target="_blank">Page</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2506.20254" target="_blank">Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement</a><br>
			Kun Yuan, Tingxuan Chen, Shi Li, Joel Lavanchy, Christian Heiliger, Ege Özsoy, Yiming Huang, <b>Long Bai</b>, Nassir Navab, Vinkle Srivastav, Hongliang Ren, Nicolas Padoy <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2025. <br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/CAMMA-public/SPA" target="_blank">Code</a>]
			</p>
	
		<li>
			<a href="https://www.arxiv.org/abs/2506.16263" target="_blank">CapsDT: Diffusion-Transformer for Capsule Robot Manipulation</a><br>
			Xiting He, Mingwu Su, Xinqi Jiang, <b>Long Bai</b>, Hongliang Ren <br>
			<em>IEEE/RSJ International Conference on Intelligent Robots and Systems</em> (<i><b>IROS</b></i>), 2025. <i><p style="color: red; display: inline;">(Oral)</p></i> <br>
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2501.19319" target="_blank">Advancing Dense Endoscopic Reconstruction with Gaussian Splatting-driven Surface Normal-aware Tracking and Mapping</a><br>
			Yiming Huang*, Beilei Cui*, <b>Long Bai*</b>, Zhen Chen, Jinlin Wu, Zhen Li, Hongbin Liu, Hongliang Ren <br>
			<em>IEEE International Conference on Robotics and Automation</em> (<i><b>ICRA</b></i>), 2025. <br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/lastbasket/Endo-2DTAM" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2411.18884" target="_blank">ETSM: Automating Dissection Trajectory Suggestion and Confidence Map-Based Safety Margin Prediction for Robot-assisted Endoscopic Submucosal Dissection</a><br>
			Mengya Xu, Wenjin Mo, Guankun Wang, Huxin Gao, An Wang, <b>Long Bai</b>, Chaoyang Lyu, Xiaoxiao Yang, Zhen Li, Hongliang Ren <br>
			<em>IEEE International Conference on Robotics and Automation</em> (<i><b>ICRA</b></i>), 2025. <br>
			<font color="red">(MRC Symposium 2025 Best Application Award)</font></br> 
		</li>
			<p style="margin-top:3px">
				
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2409.12467" target="_blank">SurgPLAN++: Universal Surgical Phase Localization Network for Online and Offline Inference</a><br>
			Zhen Chen, Xingjian Luo, Jinlin Wu, <b>Long Bai</b>, Zhen Lei, Hongliang Ren, Sebastien Ourselin, Hongbin Liu <br>
			<em>IEEE International Conference on Robotics and Automation</em> (<i><b>ICRA</b></i>), 2025. <br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/lxj22/SurgPLAN-Plus" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://openreview.net/pdf?id=Fb0q2uI4Ha" target="_blank">TAU-106K: A New Dataset for Comprehensive Understanding of Traffic Accident</a><br>
			Yixuan Zhou*, <b>Long Bai*</b>, Sijia Cai, Bing Deng, Xing Xu, Heng Tao Shen <br>
			<em>International Conference on Learning Representations</em> (<i><b>ICLR</b></i>), 2025. <br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/cool-xuan/TABot" target="_blank">Code & Data</a>]
			</p>
		
		<li>
			<a href="https://openreview.net/forum?id=ZsU52Zkzjr" target="_blank">PvNeXt: Rethinking Network Design and Temporal Motion for Point Cloud Video Recognition</a><br>
			Jie Wang, Tingfa Xu, Lihe Ding, Xinjie Zhang, <b>Long Bai</b>, Jianan Li <br>
			<em>International Conference on Learning Representations</em> (<i><b>ICLR</b></i>), 2025. <br>
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2406.13705" target="_blank">EndoUIC: Promptable Diffusion Transformer for Unified Illumination Correction in Capsule Endoscopy</a><br>
			<b>Long Bai*</b>, Tong Chen*, Qiaozhi Tan*, Wan Jun Nah, Yanheng Li, Zhicheng He, Sishen Yuan, Jinlin Wu, Zhen Chen, Mobarakol Islam, Zhen Li, Hongbin Liu, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2024. <br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/EndoUIC" target="_blank">Code & Data</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2401.16416" target="_blank">Endo-4DGS: Endoscopic Monocular Scene Reconstruction with 4D Gaussian Splatting</a><br>
			Yiming Huang*, Beilei Cui*, <b>Long Bai*</b>, Ziqi Guo, Mengya Xu, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2024. <br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/lastbasket/Endo-4DGS" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2405.10550" target="_blank">LighTDiff: Surgical Endoscopic Image Low-Light Enhancement with T-Diffusion</a><br>
			Tong Chen*, Qingcheng Lyu*, <b>Long Bai*</b>, Erjian Guo, Huxin Gao, Xiaoxiao Yang, Hongliang Ren, Luping Zhou <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2024. <i><p style="color: red; display: inline;">(Early Accepted)</p></i> <br> 
			<font color="red">(MICCAI Best Paper Runner Up, Top 3 out of 2771 Submissions)</font></br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/DavisMeee/LighTDiff" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2405.08672" target="_blank">EndoDAC: Efficient Adapting Foundation Model for Self-Supervised Depth Estimation from Any Endoscopic Camera</a><br>
			Beilei Cui*, Mobarakol Islam*, <b>Long Bai*</b>, An Wang, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2024. <i><p style="color: red; display: inline;">(Early Accepted)</p></i> <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/BeileiCui/EndoDAC" target="_blank">Code</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2407.19435" target="_blank">ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding</a><br>
			Zhen Chen, Zongmin Zhang, Wenwu Guo, Xingjian Luo, <b>Long Bai</b>, Jinlin Wu, Hongliang Ren, Hongbin Liu <br>
			<em>IEEE/RSJ International Conference on Intelligent Robots and Systems</em> (<i><b>IROS</b></i>), 2024. <i><p style="color: red; display: inline;">(Oral)</p></i> <br>
			<!-- <font color="red">(Oral)</font></br> -->
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/Zonmgin-Zhang/ASI-Seg" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="http://arxiv.org/abs/2402.06985" target="_blank">OSSAR: Towards Open-Set Surgical Activity Recognition in Robot-assisted Surgery</a><br>
			<b>Long Bai*</b>, Guankun Wang*, Jie Wang, Xiaoxiao Yang, Huxin Gao, Xin Liang, An Wang, Mobarakol Islam, Hongliang Ren <br>
			<em>IEEE International Conference on Robotics and Automation</em> (<i><b>ICRA</b></i>), 2024. <br>
			<font color="red">(IEEE RAS Travel Grant Award)</font></br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/OSSAR" target="_blank">Code</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2407.20213" target="_blank">Registering Neural 4D Gaussians for Endoscopic Surgery</a><br>
			Yiming Huang, Beilei Cui, Ikemura Kei, Jiekai Zhang, <b>Long Bai</b>, Hongliang Ren <br>
			<em>IEEE International Conference on Robotics and Biomimetics</em> (<i><b>ROBIO</b></i>), 2024. <br>
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2411.02410" target="_blank">Markerless Platform-independent Web-Based Augmented Reality with Auto-Scaling and Real-Time Head Tracking towards Neurointerventional Preoperative Planning and Training of Head-mounted Robotic Needle Insertion</a><br>
			Hon Lung Ho, Yupeng Wang, An Wang, <b>Long Bai</b>, Hongliang Ren <br>
			<em>IEEE International Conference on Robotics and Biomimetics</em> (<i><b>ROBIO</b></i>), 2024. <br>
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2402.11476" target="_blank">EndoOOD: Uncertainty-aware Out-of-distribution Detection in Capsule Endoscopy Diagnosis</a><br>
			Qiaozhi Tan*, <b>Long Bai*</b>, Guankun Wang*, Mobarakol Islam, Hongliang Ren <br>
			<em>IEEE International Symposium on Biomedical Imaging</em> (<i><b>ISBI</b></i>), 2024. <br> 
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2406.10508" target="_blank">Learning to Adapt Foundation Model DINOv2 for Capsule Endoscopy Diagnosis</a><br>
			Bowen Zhang*, Ying Chen*, <b>Long Bai</b>, Yan Zhao, Yuxiang Sun, Yixuan Yuan, Jianhua Zhang, Hongliang Ren <br>
			<em>International Conference on Biomimetic Intelligence and Robotics & Medical Robotics Forum</em> (<i><b>ICBIR</b></i>), 2024. <br>
		</li>
			<p style="margin-top:3px">
				
			</p>	

		<li>
			<a href="https://link.springer.com/chapter/10.1007/978-3-031-61041-7_15" target="_blank">Affecting Audience Valence and Arousal in 360 Immersive Environments: How Powerful Neural Style Transfer Is?</a><br>
			Yanheng Li, <b>Long Bai</b>, Yaxuan Mao, Xuening Peng, Zehao Zhang, Antoni B. Chan, Jixing Li, Xin Tong, Ray LC <br>
			<em>International Conference on Human-Computer Interaction</em> (<i><b>HCII</b></i>), 2024. <br>
		</li>
			<p style="margin-top:3px">
				
			</p>	
		<li>
			<a href="https://arxiv.org/abs/2309.10431" target="_blank">Sample-adaptive Augmentation for Point Cloud Recognition Against Real-world Corruptions</a><br>
			Jie Wang, Lihe Ding, Tingfa Xu, Shaocong Dong, Xinli Xu, <b>Long Bai</b>, Jianan Li <br>
			<em>International Conference on Computer Vision</em> (<i><b>ICCV</b></i>), 2023. <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/Roywangj/AdaptPoint" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2307.02452" target="_blank">LLCaps: Learning to Illuminate Low-Light Capsule Endoscopy with Curved Wavelet Attention and Reverse Diffusion</a><br>
			<b>Long Bai*</b>, Tong Chen*, Yanan Wu, An Wang, Mobarakol Islam, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2023. <i><p style="color: red; display: inline;">(Oral, Top 3%)</p></i> <br>  
			<!-- <font color="red">(Oral, Top 3%)</font></br> -->
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/LLCaps" target="_blank">Code & Data</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2307.05182" target="_blank">CAT-ViL: Co-Attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery</a><br>
			<b>Long Bai*</b>, Mobarakol Islam*, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2023. <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/CAT-ViL" target="_blank">Code</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2307.12045" target="_blank">Revisiting Distillation for Continual Learning on Visual Question Localized-Answering in Robotic Surgery</a><br>
			<b>Long Bai*</b>, Mobarakol Islam*, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2023. <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/CS-VQLA" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2308.02845" target="_blank">Landmark Detection using Transformer Toward Robot-assisted Nasal Airway Intubation</a><br>
			Tianhang Liu, Hechen Li, <b>Long Bai†</b>, Yanan Wu, An Wang, Mobarakol Islam, Hongliang Ren <br>
			<em>International Conference on Biomimetic Intelligence and Robotics & Medical Robotics Forum</em> (<i><b>ICBIR</b></i>), 2023. <br>
			<font color="red">(Best Student Paper Award)</font></br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/ConorLTH/airway_intubation_landmarks_detection" target="_blank">Code</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2308.02869" target="_blank">Semi-supervised Learning for Segmentation of Bleeding Regions in Video Capsule Endoscopy</a><br>
			Hechen Li, Yanan Wu, <b>Long Bai†</b>, An Wang, Tong Chen, Hongliang Ren <br>
			<em>International Conference on Biomimetic Intelligence and Robotics & Medical Robotics Forum</em> (<i><b>ICBIR</b></i>), 2023. <br>
		</li>
			<p style="margin-top:3px">
				
			</p>	
		
		<li>
			<a href="https://arxiv.org/abs/2305.11692" target="_blank">Surgical-VQLA: Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery</a><br>
			<b>Long Bai*</b>, Mobarakol Islam*, Lalithkumar Seenivasan, Hongliang Ren <br>
			<em>IEEE International Conference on Robotics and Automation</em> (<i><b>ICRA</b></i>), 2023. <br>
			<font color="red">(IEEE RAS Travel Grant Award)</font></br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/Surgical-VQLA" target="_blank">Code & Data</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2305.10955" target="_blank">Deep Reinforcement Learning-Based Control for Stomach Coverage Scanning of Wireless Capsule Endoscopy</a><br>
			Yameng Zhang*, <b>Long Bai*</b>, Li Liu, Hongliang Ren, Max Q–H Meng <br>
			<em>IEEE International Conference on Robotics and Biomimetics</em> (<i><b>ROBIO</b></i>), 2022. <br>
		</li>
			<p style="margin-top:3px">
				
			</p>

		<li>
			<a href="https://arxiv.org/abs/2108.03026" target="_blank">The Influence of Age and Gender Information on the Diagnosis of Diabetic Retinopathy: Based on Neural Networks</a><br>
			<b>Long Bai*</b>, Sihang Chen*, Mingyang Gao*, Leila Abdelrahman, Manal Al Ghamdi, Mohamed Abdel-Mottaleb <br>
			<em>Annual International Conference of the IEEE Engineering in Medicine & Biology Society</em> (<i><b>EMBC</b></i>), 2021. <br>
		</li>
			<p style="margin-top:3px">
				
			</p>
	</ul>
	
<h3>Workshop Papers</h3>
	<ul>
		<li>
			<a href="https://arxiv.org/abs/2405.10948" target="_blank">Surgical-LVLM: Learning to Adapt Large Vision-Language Model for Grounded Visual Question Answering in Robotic Surgery</a><br>
			Guankun Wang*, <b>Long Bai*</b>, Wan Jun Nah, Jie Wang, Zhaoxi Zhang, Zhen Chen, Jinlin Wu, Mobarakol Islam, Hongbin Liu, Hongliang Ren <br>
			<em>ICLR FM-Wild Workshop</em>, 2025. <br>
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="http://arxiv.org/abs/2410.18698" target="_blank">Transferring Knowledge from High-Quality to Low-Quality MRI for Adult Glioma Diagnosis</a><br>
			Yanguang Zhao, <b>Long Bai†</b>, Zhaoxi Zhang, Yanan Wu, Mobarakol Islam, Hongliang Ren <br>
			<em>MICCAI BraTS-SSA Challenge</em>, 2024. <br> 
			<font color="red">(Runner Up of Top-performing Team)</font></br> 
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2408.04426" target="_blank">A Review of 3D Reconstruction Techniques for Deformable Tissues in Robotic Surgery</a><br>
			Mengya Xu, Ziqi Guo, An Wang, <b>Long Bai</b>, Hongliang Ren <br>
			<em>MICCAI EARTH Workshop</em>, 2024. <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/Epsilon404/surgicalnerf" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2404.10640" target="_blank">Adapting SAM for Surgical Instrument Tracking and Segmentation in Endoscopic Submucosal Dissection Videos</a><br>
			Jieming Yu, <b>Long Bai†</b>, Guankun Wang, An Wang, Xiaoxiao Yang, Huxin Gao, Hongliang Ren <br>
			<em>IEEE ICRA C4SR+ Workshop</em>, 2024. <br> 
			<font color="red">(Best Poster Award)</font></br> 
		</li>
			<p style="margin-top:3px">
				
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2305.11686" target="_blank">Domain Adaptive Sim-to-Real Segmentation of Oropharyngeal Organs Towards Robot-assisted Intubation</a><br>
			Guankun Wang, Tian-Ao Ren, Jiewen Lai, <b>Long Bai†</b>, Hongliang Ren <br>
			<em>IEEE ICRA Workshop on New Evolutions in Surgical Robotics</em>, 2023. <br>
			<font color="red">(Best Poster Award)</font></br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/gkw0010/EISOST-Sim2Real-Dataset-Release" target="_blank">Dataset</a>]
			</p>	

		<li>
			<a href="https://ieeexplore.ieee.org/document/10108633" target="_blank">The Exploration and Evaluation of Using Neural Style Transfer in Generating Affective 360° Panoramic VR Environments</a><br>
			Yanheng Li, <b>Long Bai</b>, Yaxuan Mao, Xuening Peng, Zehao Zhang, Xin Tong, Ray LC <br>
			<em>IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops</em>, 2023. <br>
		</li>
			<p style="margin-top:3px">

			</p>	
	</ul>


</tbody></table>






<h2>Professional Services</h2>

<li>	
	<b>Associate Editor:</b>
	<br>
	<span style="display: block; margin-top: 0.5em;"></span>
	<a href="https://ieee-robio.org/2024/" target="_blank">IEEE International Conference on Robotics and Biomimetics (ROBIO) 2024 </a> <br> 
	<!-- <p style="margin-top:3px"></p> -->		
</li>

<li>	
	<b>Organizing Chair:</b>
	<br>
	<span style="display: block; margin-top: 0.5em;"></span>
	
	<a href="https://sites.google.com/view/iros-2025-c4sr/home" target="_blank">IROS 2025 C4SR+ Workshop: Continuum, Compliant, Cooperative, Cognitive Surgical Robotic Systems in the Embodied AI Era</a> <br>
    	<a href="https://sites.google.com/view/ema4miccai2025/home" target="_blank">The 1st MICCAI Workshop on Efficient Medical AI (EMA4MICCAI) 2025 </a> <br>
	<!-- <p style="margin-top:3px"></p> -->		
</li>

<li>	
	<b>Program Committee:</b>
	<br>
	<span style="display: block; margin-top: 0.5em;"></span>
    	<a href="https://earth-workshop.github.io/" target="_blank">MICCAI 2024 Workshop on Embodied AI and Robotics for Healthcare (EARTH) </a> <br> 
    	<a href="https://icmi.acm.org/2023/late-breaking-results/" target="_blank">ACM International Conference on Multimodal Interaction (ICMI) 2023 LBR </a> <br> 
	<!-- <p style="margin-top:3px"></p> -->		
</li>
	
<li>	
	<b>Regular Reviewer:</b>
	<br>
	<span style="display: block; margin-top: 0.5em;"></span>
    	NeurIPS, ICLR, MICCAI, CoRL, ICRA, IROS, IPCAI, ISBI, CHI, VR, CSCW, IUI, ROBIO<br>
	<span style="display: block; margin-top: 0.5em;"></span>
	T-PAMI, T-MI, T-NNLS, T-CSVT, T-ASE, T-IM, RA-L, OJ-IM, IEEE Sensors Journal, MedIA, Information Fusion, Information Sciences, CMIG, AIIM, CBM, MBEC, JSCE, JMRR<br>
	<!-- <p style="margin-top:3px"></p> -->		
</li>	

	<!-- <b>Regular Reviewer:</b>
	<br>	
	<table style="border-spacing:2px">
	<tbody>
		<tr>
			<td>Conferences: </td><td>MICCAI, ICRA, IROS, IPCAI, ISBI, CHI, VR, CSCW, ETRA, IUI, ROBIO, ICBIR</td>	
		</tr>
		<tr>
			<td>Journals: </td><td>IEEE TPAMI, IEEE TMI, IEEE TCSVT, IEEE TIM, IEEE RAL, IEEE OJIM, IEEE Sensors Journal, Information Fusion, Information Sciences, Computers in Biology and Medicine, Medical & Biological Engineering & Computing, JSCE, JMRR</td>
		</tr>
	</tbody>
	</table>
	<br> -->
	
<h2>Invited Talks</h2>
<li>Surgical Visual Question Localized-Answering.<br>
Pre-ICRA Online,  May. 2023.
</li>
<li>Lifelong Learning: Background, Methodology, and Applications.<br>
Hong Kong University of Science and Technology (HKUST), Oct. 2022.
</li>

<h2>Teaching</h2>
	<b>Teaching Assistant:</b>
	<br>	
	<table style="border-spacing:2px">
	<tbody>
		<tr>
			<td> 2024-2025 </td><td> Spring </td><td> ELEG5757 </td><td> Intelligent Wearable Electronics </td>
		</tr>
		<tr>
			<td> 2024-2025 </td><td> Spring </td><td> ELEG3103 </td><td> Robotic Perception and Intelligence </td>
		</tr>
		<tr>
			<td> 2023-2024 </td><td> Spring </td><td> ELEG5600 </td><td> Advanced Perception for Intelligent Robotics </td>
		</tr>
		<tr>
			<td> 2023-2024 </td><td>Fall </td><td> ENGG2760 </td><td> Probability for Engineers </td>
		</tr>
		<tr>
			<td> 2022-2023 </td><td> Spring </td><td> ELEG5757 </td><td> Intelligent Wearable Electronics </td>
		</tr>
		<tr>
			<td> 2022-2023 </td><td> Fall </td><td> ENGG2760 </td><td> Probability for Engineers </td>
		</tr>
        	<tr>
			<td> 2021-2022 </td><td> Spring </td><td> ELEG3201 </td><td> Microelectronic Devices and Circuits </td>
		</tr>
		<tr>
			<td> 2021-2022 </td><td> Fall </td><td> ENGG2760 </td><td> Probability for Engineers </td>
		</tr>
	</tbody>
	</table>
	<br>	
	
	<b>Mentees:</b>
	<br>
	<table style="border-spacing:2px">
	<body>
	<tr>
		<td> Junyi Wang </td><td> Intern 2024-2025 </td><td> </td>
	</tr>
	<tr>
		<td> <a href="https://hezhicheng2002.github.io/" target="_blank">Zhicheng He</a> </td><td> Intern 2024-2025 </td><td> -> Research Master, NUS </td>
	</tr>
	<tr>
		<td> Xinyu Ma </td><td> Intern 2024-2025 </td><td> -> Ph.D. Student, MPU </td>
	</tr>
	<tr>
		<td> Yanguang Zhao </td><td> Intern 2024-2025 </td><td> -> M.Sc. Student, NUS </td>
	</tr>
	<tr>
		<td> <a href="https://scholar.google.com/citations?hl=en&user=ssesMYEAAAAJ" target="_blank">Zhaoxi Zhang</a> </td><td> Intern 2024-2025 </td><td> -> M.Phil. Student, PKU </td>
	</tr>
	<tr>
		<td> <a href="https://www.linkedin.com/in/jieming-yu-454b63256/?originalSubdomain=hk" target="_blank">Jieming Yu</a> </td><td> Intern 2023-2025 </td><td> -> Ph.D. Student, HKUST </td>
	</tr>	
	<tr>
		<td> <a href="https://www.linkedin.com/in/boyi-ma-527b9b350/?originalSubdomain=ca" target="_blank">Boyi Ma</a> </td><td> Intern 2023-2024 </td><td> -> Ph.D. Student, UofT </td>
	</tr>
	<tr>
		<td> <a href="https://roksanne.github.io/" target="_blank">Ruohan Wang</a> </td><td> Intern 2023-2024 </td><td> -> Ph.D. Student, Brown </td>
	</tr>
	<tr>
		<td> <a href="https://dblp.org/pid/369/3167.html" target="_blank">Qiaozhi Tan</a> </td><td> Intern 2023-2024 </td><td> -> Ph.D. Student, CityU HK </td>
	</tr>
	<tr>
		<td> <a href="https://www.linkedin.com/in/yihan-ma-b5b070283/" target="_blank">Yihan Ma</a> </td><td> Intern 2023-2024 </td><td> -> M.Sc. Student, UCL </td>
	</tr>
	<tr>
		<td> Tianhang Liu </td><td> CUHK M.Sc. 2022-2023 </td><td> -> R&D, ASTRI HK </td>
	</tr>
	<tr>
		<td> <a href="https://gkw0010.github.io/" target="_blank">Guankun Wang</a> </td><td> Intern 2022-2023 </td> <td> -> Ph.D. Student, CUHK </td>
	</tr>
	<tr>
		<td> <a href="https://www.linkedin.com/in/yuanhaozhao1998/" target="_blank">Yuanhao Zhao</a> </td><td> CUHK M.Sc. 2021-2022 </td><td> -> R&D, Samsung China </td>
	</tr>
	<tr>
		<td> <a href="https://scholar.google.com/citations?user=mGkM_WgAAAAJ&hl=en" target="_blank">Liangyu Wang</a> </td><td> CUHK M.Sc. 2021-2022 </td><td> -> Ph.D. Student, KAUST </td>
	</tr>
	<tr>
		<td> <a href="https://davismeee.github.io/" target="_blank">Tong Chen</a> </td><td> Intern 2021-2022 </td><td> -> Ph.D. Student, USYD </td>
	</tr>
	</tbody>
	</table>
<br>

<h2>Some Links</h2>
<li><a href="http://www.labren.org/mm/" target="_blank">Lab of Robotics, Embodied AI, and Navigation in Vivo</a>, CUHK.<br>
</li>
<li><a href="https://www.cs.cit.tum.de/camp/start/" target="_blank">Chair for Computer Aided Medical Procedures & Augmented Reality (CAMP)</a>, TUM.<br>
</li>
<li><a href="https://www.cs.cit.tum.de/camp/members/long-bai/" target="_blank">CAMP Personal Page</a>, TUM.<br>
</li>
	
<div id="footer">
	<div id="footer-text"></div>
</div>
	<p><center>
	<div id="clustrmaps-widget" style="width:10%">
		<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=QW1b-GJYj119mme9wSJ8T-_BmnDNjhQcaK_IFmm8y1o"></script>
	</div>
		
	<br>
        &copy; Long Bai | Last updated: June 2025
     
      </center></p>


</div>
</body></html>
