<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Long Bai, Bai Long, EE, Electronic Engineering, CUHK, The Chinese University of Hong Kong, Hongliang Ren"> 
<meta name="description" content="Long Bai&#39;s home page">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Long Bai's&#39;s Homepage</title>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
</head>
<body>
<div id="layout-content" style="margin-top:25px">



<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Long Bai</h1><h1>
				</h1></div>

				<h3>Ph.D. Candidate</h3>
				<p>
					Department of Electronic Engineering <br>
					The Chinese University of Hong Kong <br>
					
					<!--<p style="color:#FF0000";> I will graduate in mid-2025 and am looking for an industrial position!</p>-->
					<br>
					Office: Room 424, Ho Sin-Hang Engineering Building, CUHK, Shatin, N.T., Hong Kong <br>
					Email: b.long@link.cuhk.edu.hk <br>
				
				</p>
				<p> 	<a href="https://scholar.google.com/citations?user=v-fw-98AAAAJ&hl=en"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/longbai1006"><img src="./pic/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://orcid.org/0000-0002-9762-6821"><img src="./pic/orcid.jpeg" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://www.researchgate.net/profile/Long-Bai-13"><img src="./pic/rg.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://www.linkedin.com/in/long-bai-0a37b71a5/"><img src="./pic/LinkedIn_s.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="./pic/WeChat_Long.jpeg"><img src="./pic/wechat.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://wa.me/85259607217/"><img src="./pic/whatsapp.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="mailto:b.long@link.cuhk.edu.hk"><img src="./pic/email.jpeg" height="30px" style="margin-bottom:-3px"></a>
					<!--
					<a href="https://twitter.com/longbaijerry"><img src="./pic/twitter.png" height="30px" style="margin-bottom:-3px"></a>					
					<a href="https://zh-cn.facebook.com/people/Lequan-Yu/100003696557697"><img src="./pic/Facebook_s.png" height="30px" style="margin-bottom:-3px"></a>
					-->
				</p>
			</td>
			<td>
				<img src="./pic/Long.jpg" border="0" width="200"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>
<!--
[<a href="./pic/CV-English-BaiLong.pdf">CV</a>]|[<a href="./pic/CV-Chinese-BaiLong.pdf">简历</a>]
-->
<h2>Biography </h2>
<p>
	I am a 4th-year Ph.D. candidate at <a href="https://www.ee.cuhk.edu.hk/en-gb/">Department of Electronic Engineering</a>, <a href="https://www.cuhk.edu.hk/english/index.html">The Chinese University of Hong Kong (CUHK)</a>, advised by <a href="https://www.ee.cuhk.edu.hk/en-gb/people/academic-staff/professors/prof-ren-hongliang" target="_blank">Prof. Hongliang Ren</a> and <a href="https://www.ee.cuhk.edu.hk/en-gb/people/academic-staff/professors/prof-lai-jiewen" target="_blank">Prof. Jiewen Lai</a>. Previously, I received the B. Sc. degree in Opto-Electronics Information Science and Engineering from <a href="https://english.bit.edu.cn/">Beijing Institute of Technology (BIT)</a> in 2021, advised by <a href="https://opt.bit.edu.cn/jsdw/jsml/gdcxyxxgcyjs/c748795cd272417f9e5733a068db1962.htm" target="_blank">Prof. Kun Gao</a>. I am fortunate to have been working with <a href="https://mobarakol.github.io/" target="_blank">Dr. Mobarakol Islam</a> (UCL), <a href="https://www.cs.cit.tum.de/camp/members/cv-nassir-navab/nassir-navab/" target="_blank">Prof. Nassir Navab</a> (TUM), <a href="https://www.cs.cit.tum.de/camp/members/zhongliang-jiang/" target="_blank">Dr. Zhongliang Jiang</a> (TUM), <a href="https://scholar.google.com/citations?user=UsCotVMAAAAJ&hl=en" target="_blank">Prof. Mohamed Abdel-Mottaleb</a> (UMiami), and <a href="https://scholar.google.com/citations?user=OJUbSAMAAAAJ&hl=en" target="_blank">Yanheng Li</a> (CityU HK).
	<!--Previously, I received the B. Sc. degree from Opto-Electronics Information Science and Engineering at <a href="https://english.bit.edu.cn/">Beijing Institute of Technology</a> in 2021.</p>--> 
</p>

<p>My research interests include artificial intelligence and its applications in medical image computing, robotic perception, and surgical data science. I recently work on multimodal large language models (MLLMs) and diffusion models for low-level vision.</p>
<!--<p>My research interests include medical image computing, robotic video perception, and artificial intelligence. Specifically, I am dedicated to developing learning algorithms for complex time-series medical data analysis, applied primarily to endoscopy and robotic surgery. I recently work on data efficient learning to minimize human annotation.</p>-->

<!--<p style="color:red;"> <b>*Opening!*</b> XXX </p>-->

<!-- <p>If you are interested in joining <a href="http://www.labren.org/mm/">Ren Lab</a> as a research intern, feel free to drop me an email! CUHK undergraduate/MSc students may check our <a href="https://www.osa.cuhk.edu.hk/flourishingcuhk/student-helper-engagement-scheme/for-students/">Student Helper</a> programme. Collaboration is also welcome!</p> -->

<!--<p style="color:red;">
	<a href="https://www.ucl.ac.uk/surgical-robot-vision/"> SRV group, WEISS</a> is looking for self-motivated summer interns (2022), to work on the research areas of robotic surgery intelligence and surgical 3D vision. Welcome to drop me an email with your CV. Remote collaboration is also welcome.
</p>-->

<h2>News</h2>
<div style="height: 280px; overflow: auto;">
<ul>
	<li>
		[09/2024] Our paper <a href="https://arxiv.org/abs/2405.10550" target="_blank">LighTDiff</a> is selected in <b>MICCAI 2024 Best Paper and Young Scientist Award Shortlist</b>.
	</li>
	<li>
		[07/2024] One paper <a href="https://arxiv.org/abs/2408.04958" target="_blank">Surgical-VQLA++</a> is accepted by <a href="https://www.sciencedirect.com/journal/information-fusion" target="_blank">Information Fusion</a> (IF: 14.7).
	</li>
	<li>
		[07/2024] I am awarded the <b>PhD International Mobility for Partnerships and Collaborations (IMPAC) Award</b>.
	</li>
	<li>
		[06/2024] One paper <a href="https://arxiv.org/abs/2407.19435" target="_blank">ASI-Seg</a> is accepted by <a href="https://iros2024-abudhabi.org/" target="_blank">IROS 2024</a> as <b>Oral</b> Presentation.
	</li>
	<li>
		[06/2024] Our <a href="http://arxiv.org/abs/2401.06013" target="_blank">Surgical-DINO</a> is selected as <b>Long Oral</b> and receives the <b>IPCAI 2024 Best Paper Award Shortlist</b>!
	</li>
	<li>
		[06/2024] Four papers are accepted by <a href="https://conferences.miccai.org/2024/en/" target="_blank">MICCAI 2024</a> (with <b>2 early accepted</b> & <b>1 oral</b>)!
	</li>
	<li>
		[05/2024] I am awarded the <b>CUHK Overseas Research Attachment Scholarship</b> 2024-2025.
	</li>
	<li>
		[05/2024] Our poster on surgical instrument tracking receives the <b>Best Poster Award</b> in <a href="https://sites.google.com/view/icra24-c4sr" target="_blank">ICRA 2024 C4SR+ Workshop</a>!
	</li>
	<li>
		[02/2024] One paper <a href="https://arxiv.org/abs/2402.05860" target="_blank">CAT-SD</a> is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=42" target="_blank">IEEE TMI</a> (IF: 8.9).
	</li>
	<li>
		[02/2024] One paper <a href="https://arxiv.org/abs/2402.11476" target="_blank">EndoOOD</a> is accepted by <a href="https://biomedicalimaging.org/2024/" target="_blank">ISBI 2024</a>.
	</li>
	<li>
		[01/2024] One paper <a href="http://arxiv.org/abs/2402.06985" target="_blank">OSSAR</a> is accepted by <a href="https://2024.ieee-icra.org/" target="_blank">ICRA 2024</a> with the <b>IEEE RAS Travel Grant Award</b>.
	</li>
	<li>
		[01/2024] One paper on AI-assisted needle insertion simulator is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7361" target="_blank">IEEE Sensors Journal</a>.
	</li>
	<li>
		[12/2023] One paper <a href="http://arxiv.org/abs/2401.06013" target="_blank">Surgical-DINO</a> is <b>early accepted</b> by <a href="https://sites.google.com/view/ipcai2024/home" target="_blank">IPCAI 2024</a>.
	</li>
	<li>
		[12/2023] One paper on style transfer for VR is accepted by <a href="https://2024.hci.international" target="_blank">HCII 2024</a>.
	</li>
	<li>
		[10/2023] One paper on multimodal image fusion is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7361" target="_blank">IEEE Sensors Journal</a>.
	</li>
	<li>
		[09/2023] One paper on pain communication is accepted by <a href="https://www.frontiersin.org/journals/physiology" target="_blank">Frontiers in Physiology</a>.
	</li>
	<li>
		[08/2023] One paper <a href="https://arxiv.org/abs/2308.14100" target="_blank">EndoCSS</a> is accepted by <a href="https://www.sciencedirect.com/journal/computers-in-biology-and-medicine" target="_blank">Computers in Biology and Medicine</a>.
	</li>
	<li>
		[07/2023] One paper <a href="https://arxiv.org/abs/2309.10431" target="_blank">AdaptPoint</a> is accepted by <a href="https://iccv2023.thecvf.com/" target="_blank">ICCV 2023</a>.
	</li>
	<li>
		[07/2023] I passed my Ph.D. proposal defense and became a Ph.D. candidate! 
	</li>
	<li>
		[07/2023] Our paper on intubation landmark detection receives the <b>ICBIR 2023 Best Student Paper Award</b>!
	</li>
	<li>
		[07/2023] Two papers are accepted by <a href="http://www.icbir.org/" target="_blank">ICBIR 2023</a>.
	</li>
	<li>
		[06/2023] One paper on CT airway extraction is accepted by <a href="https://www.sciencedirect.com/journal/artificial-intelligence-in-medicine" target="_blank">Artificial Intelligence in Medicine</a>. 
	</li>
	<li>
		[06/2023] One paper on pulmonary vessel segmentation is accepted by <a href="https://www.springer.com/journal/11517" target="_blank">MBEC</a> Journal.
	</li>
	<li>
		[06/2023] One paper on oropharyngeal organ sim-to-real segmentation is accepted by <a href="https://www.springer.com/journal/11517" target="_blank">MBEC</a> Journal.
	</li>
	<li>
		[06/2023] Three papers <a href="https://arxiv.org/abs/2307.02452" target="_blank">LLCaps</a>, <a href="https://arxiv.org/abs/2307.05182" target="_blank">CAT-ViL</a> and <a href="https://arxiv.org/abs/2307.12045" target="_blank">CS-VQLA</a> are accepted by <a href="https://conferences.miccai.org/2023/en/" target="_blank">MICCAI 2023</a> (1 <b>oral</b> & 2 <b>posters</b>).
	</li>
	<li>
		[06/2023] One paper on deep learning-assisted micro force sensing is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19" target="_blank">IEEE TIM</a>.
	</li>
	<li>
		[06/2023] Our poster on sim-to-real receives the <b>Best Poster Award</b> in <a href="https://sites.google.com/view/icra2023workshop-surgicalrobot/" target="_blank">ICRA 2023 Workshop on Surgical Robotics</a>!
	</li>
	<li>
		[01/2023] One paper <a href="https://ieeexplore.ieee.org/document/10160403" target="_blank">Surgical-VQLA</a> is accepted by <a href="https://www.icra2023.org/" target="_blank">ICRA 2023</a> with the <b>IEEE RAS Travel Grant Award</b>.
	</li>
	<li>
		[01/2023] One poster is accepted by <a href="https://ieeevr.org/2023/" target="_blank">IEEE VR 2023</a>.
	</li>
	<li>
		[10/2022] One paper on reinforcement learning and stomach coverage of WCE is accepted by <a href="https://irmv.sjtu.edu.cn/robio2022/" target="_blank">ROBIO 2022</a>.
	</li>
</ul>
</div>


<h2>Selected Awards</h2>
<table style="border-spacing:2px">
		<body>
		<tr><td> 2024, MICCAI Best Paper and Young Scientist Award Shortlist</td></tr>
		<tr><td> 2024, PhD International Mobility for Partnerships and Collaborations (IMPAC) Award</td></tr>
		<tr><td> 2024, IPCAI Best Paper Award Shortlist</td></tr>
		<tr><td> 2024, CUHK Overseas Research Attachment Scholarship</td></tr>
		<tr><td> 2024, Best Poster Award of ICRA 2024 C4SR+ Workshop</td></tr>
		<tr><td> 2024, IEEE ICRA RAS Travel Grants Award</td></tr>
		<tr><td> 2023, ICBIR Best Student Paper Award</td></tr>
		<tr><td> 2023, Best Poster Award of IEEE ICRA Workshop on Surgical Robotics</td></tr>
		<tr><td> 2023, IEEE ICRA RAS Travel Grants Award</td></tr>
		<tr><td> 2021, Merit Award of EMedIC Global</td></tr>
		<tr><td> 2021-2025, CUHK Vice-Chancellor's Ph.D. Scholarship Scheme</td></tr>
    	<!--<tr><td> BIT Academic Excellent Scholarship, 2020</td></tr>
    	<tr><td> BIT Academic Progress Scholarship, 2019</td></tr>-->
	</tbody>
</table>

<h2>Publications [Full list at <a href="https://scholar.google.com/citations?user=v-fw-98AAAAJ&hl=en">Google Scholar</a>]</h2>
	<!-- <p><font face="Arial" size="4"><b>2023</b></font></p> -->
* indicates equal contribution; † indicates project lead.
<!-- <h3><font face="Arial"> Preprints</h3> -->
<h3>Preprints</h3>
	<ul>

		<li>
			<a href="https://arxiv.org/abs/2408.04593" target="_blank">SAM 2 in Robotic Surgery: An Empirical Evaluation for Robustness and Generalization in Surgical Video Segmentation</a><br>
			Jieming Yu, An Wang, Wenzhen Dong, Mengya Xu, Mobarakol Islam, Jie Wang, <b>Long Bai†</b>, Hongliang Ren <br>
			<em>Preprint</em>, 2024. <br>
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2405.10948" target="_blank">Surgical-LVLM: Learning to Adapt Large Vision-Language Model for Grounded Visual Question Answering in Robotic Surgery</a><br>
			Guankun Wang*, <b>Long Bai*</b>, Wan Jun Nah, Jie Wang, Zhaoxi Zhang, Zhen Chen, Jinlin Wu, Mobarakol Islam, Hongbin Liu, Hongliang Ren <br>
			<em>Preprint</em>, 2024. <br>
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2407.20213" target="_blank">Registering Neural 4D Gaussians for Endoscopic Surgery</a><br>
			Yiming Huang, Beilei Cui, Ikemura Kei, Jiekai Zhang, <b>Long Bai</b>, Hongliang Ren <br>
			<em>Preprint</em>, 2024. <br>
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2409.12467" target="_blank">SurgPLAN++: Universal Surgical Phase Localization Network for Online and Offline Inference</a><br>
			Zhen Chen, Xingjian Luo, Jinlin Wu, <b>Long Bai</b>, Zhen Lei, Hongliang Ren, Sebastien Ourselin, Hongbin Liu <br>
			<em>Preprint</em>, 2024. <br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/lxj22/SurgPLAN-Plus" target="_blank">Code</a>]
			</p>
	</ul>
	
<h3>Journal Papers</h3>
	<ul>
		<li>
			<a href="https://arxiv.org/abs/2408.04958" target="_blank">Surgical-VQLA++: Adversarial Contrastive Learning for Calibrated Robust Visual Question-Localized Answering in Robotic Surgery </a><br>
			<b>Long Bai*</b>, Guankun Wang*, Mobarakol Islam*, Lalithkumar Seenivasan, An Wang, Hongliang Ren <br>
			<em>Information Fusion</em>, 2024. (IF: 14.7) <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/Surgical-VQLAPlus" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2402.05860" target="_blank">Privacy-Preserving Synthetic Continual Semantic Segmentation for Robotic Surgery</a><br>
			Mengya Xu*, Mobarakol Islam*, <b>Long Bai</b>, Hongliang Ren <br>
			<em>IEEE Transactions on Medical Imaging</em> (<i><b>TMI</b></i>), 2024. (IF: 8.9) <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/XuMengyaAmy/Synthetic_CAT_SD" target="_blank">Code</a>]
			</p>

		<li>
			<a href="http://arxiv.org/abs/2401.06013" target="_blank">Surgical-DINO: Adapter Learning of Foundation Models for Depth Estimation in Endoscopic Surgery</a><br>
			Beilei Cui*, Mobarakol Islam*, <b>Long Bai</b>, Hongliang Ren <br>
			<em>International Journal of Computer Assisted Radiology and Surgery</em> (<i><b>IJCARS, Presented at IPCAI</b></i>), 2024. <br>
			<font color="red">(IPCAI Best Paper Award Shortlist, Long Oral)</font></br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/BeileiCui/SurgicalDINO" target="_blank">Code</a>]
			</p>

		
		<li>
			<a href="https://ieeexplore.ieee.org/abstract/document/10413282/" target="_blank">Data-driven 3D Tactile Cues with Intermediate Soft Interfaces towards Training Needle Insertions</a><br>
			Ruijie Tang*, Shilong Yao*, <b>Long Bai</b>, Hong Yan, Max Q.-H. Meng, Hongliang Ren <br>
			<em>IEEE Sensors Journal</em>, 2024. <br> 
		</li>
			<p style="margin-top:3px">

			</p>
	
		<li>
			<a href="https://arxiv.org/abs/2308.14100" target="_blank">Rethinking Exemplars for Continual Semantic Segmentation in Endoscopy Scenes: Entropy-based Mini-Batch Pseudo-Replay</a><br>
			Guankun Wang*, <b>Long Bai*</b>, Yanan Wu, Tong Chen, Hongliang Ren <br>
			<em>Computers in Biology and Medicine</em> (<i><b>CBM</b></i>), 2023. <br> 
		</li>
			<p style="margin-top:3px">

			</p>

		<li>
			<a href="https://arxiv.org/abs/2310.09937" target="_blank">Joint Sparse Representations and Coupled Dictionary Learning in Multi-Source Heterogeneous Image Pseudo-color Fusion</a><br>
			<b>Long Bai</b>, Shilong Yao, Kun Gao, Yanjun Huang, Ruijie Tang, Hong Yan, Max Q.-H. Meng, Hongliang Ren <br>
			<em>IEEE Sensors Journal</em>, 2023. <br> 
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://www.sciencedirect.com/science/article/abs/pii/S0933365723001513" target="_blank">Two-stage Contextual Transformer-based Convolutional Neural Network for Airway Extraction from CT Images</a><br>
			Yanan Wu, Shuiqing Zhao, Shouliang Qi, Jie Feng, Haowen Pang, Runsheng Chang, <b>Long Bai</b>, Mengqi Li, Shuyue Xia, Wei Qian, Hongliang Ren <br>
			<em>Artificial Intelligence in Medicine</em> (<i><b>AIM</b></i>), 2023. <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/zhaozsq/airway_segmentation" target="_blank">Code</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2305.10883" target="_blank">Domain Adaptive Sim-to-Real Segmentation of Oropharyngeal Organs</a><br>
			Guankun Wang, Tian-Ao Ren, Jiewen Lai, <b>Long Bai</b>, Hongliang Ren <br>
			<em>Medical & Biological Engineering & Computing</em> (<i><b>MBEC</b></i>), 2023. <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/gkw0010/EISOST-Sim2Real-Dataset-Release" target="_blank">Dataset</a>]
			</p>

		<li>
			<a href="https://link.springer.com/article/10.1007/s11517-023-02872-5" target="_blank">Transformer-based 3D U-Net for Pulmonary Vessel Segmentation and Artery-vein Separation from CT Images</a><br>
			Yanan Wu, Shouliang Qi, Meihuan Wang, Shuiqing Zhao, Haowen Pang, Jiaxuan Xu, <b>Long Bai</b>, Hongliang Ren <br>
			<em>Medical & Biological Engineering & Computing</em> (<i><b>MBEC</b></i>), 2023. <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/wuyanan513/Pulmonary-Vessel-Segmentation-and-Artery-vein-Separation" target="_blank">Code</a>]
			</p>

		<li>
			<a href="https://ieeexplore.ieee.org/abstract/document/10159526" target="_blank">An RNN-LSTM Enhanced Compact and Affordable Micro Force Sensing System for Interventional Continuum Robots with Interchangeable End-Effector Instruments</a><br>
			Shilong Yao*, Ruijie Tang*, <b>Long Bai</b>, Hong Yan, Hongliang Ren, Li Liu <br>
			<em>IEEE Transactions on Instrumentation and Measurement</em>, 2023. <br> 
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="https://www.frontiersin.org/journals/physiology/articles/10.3389/fphys.2023.1248893/full" target="_blank">Rethinking Pain Communication of Patients with Alzheimer's Disease through E-textile Interaction Design</a><br>
			Yanheng Li*, <b>Long Bai*</b>, Yaxuan Mao, Hongliang Ren, Yu Qiao, Xin Tong, Ray LC <br>
			<em>Frontiers in Physiology</em>, 2023. <br> 
		</li>
			<p style="margin-top:3px">

			</p>
	</ul>
	
<h3>Conference Papers</h3>
	<ul>
		
		<li>
			<a href="https://arxiv.org/abs/2406.13705v1" target="_blank">EndoUIC: Promptable Diffusion Transformer for Unified Illumination Correction in Capsule Endoscopy</a><br>
			<b>Long Bai*</b>, Tong Chen*, Qiaozhi Tan*, Wan Jun Nah, Yanheng Li, Zhicheng He, Sishen Yuan, Jinlin Wu, Zhen Chen, Mobarakol Islam, Zhen Li, Hongbin Liu, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2024. <br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/EndoUIC" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2401.16416" target="_blank">Endo-4DGS: Endoscopic Monocular Scene Reconstruction with 4D Gaussian Splatting</a><br>
			Yiming Huang*, Beilei Cui*, <b>Long Bai*</b>, Ziqi Guo, Mengya Xu, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2024. <br>
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/lastbasket/Endo-4DGS" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2405.10550" target="_blank">LighTDiff: Surgical Endoscopic Image Low-Light Enhancement with T-Diffusion</a><br>
			Tong Chen*, Qingcheng Lyu*, <b>Long Bai*</b>, Erjian Guo, Huxin Gao, Xiaoxiao Yang, Hongliang Ren, Luping Zhou <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2024. <i><p style="color: red; display: inline;">(Early Accepted)</p></i> <br> 
			<font color="red">(MICCAI Best Paper and Young Scientist Award Shortlist)</font></br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/DavisMeee/LighTDiff" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2405.08672" target="_blank">EndoDAC: Efficient Adapting Foundation Model for Self-Supervised Depth Estimation from Any Endoscopic Camera</a><br>
			Beilei Cui*, Mobarakol Islam*, <b>Long Bai*</b>, An Wang, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2024. <i><p style="color: red; display: inline;">(Early Accepted)</p></i> <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/BeileiCui/EndoDAC" target="_blank">Code</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2407.19435" target="_blank">ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding</a><br>
			Zhen Chen, Zongmin Zhang, Wenwu Guo, Xingjian Luo, <b>Long Bai</b>, Jinlin Wu, Hongliang Ren, Hongbin Liu <br>
			<em>IEEE/RSJ International Conference on Intelligent Robots and Systems</em> (<i><b>IROS</b></i>), 2024. <i><p style="color: red; display: inline;">(Oral)</p></i> <br>
			<!-- <font color="red">(Oral)</font></br> -->
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/Zonmgin-Zhang/ASI-Seg" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2402.11476" target="_blank">EndoOOD: Uncertainty-aware Out-of-distribution Detection in Capsule Endoscopy Diagnosis</a><br>
			Qiaozhi Tan*, <b>Long Bai*</b>, Guankun Wang*, Mobarakol Islam, Hongliang Ren <br>
			<em>IEEE International Symposium on Biomedical Imaging</em> (<i><b>ISBI</b></i>), 2024. <br> 
		</li>
			<p style="margin-top:3px">

			</p>
		
		<li>
			<a href="http://arxiv.org/abs/2402.06985" target="_blank">OSSAR: Towards Open-Set Surgical Activity Recognition in Robot-assisted Surgery</a><br>
			<b>Long Bai*</b>, Guankun Wang*, Jie Wang, Xiaoxiao Yang, Huxin Gao, Xin Liang, An Wang, Mobarakol Islam, Hongliang Ren <br>
			<em>IEEE International Conference on Robotics and Automation</em> (<i><b>ICRA</b></i>), 2024. <br>
			<font color="red">(IEEE RAS Travel Grant Award)</font></br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/OSSAR" target="_blank">Code</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2406.10508" target="_blank">Learning to Adapt Foundation Model DINOv2 for Capsule Endoscopy Diagnosis</a><br>
			Bowen Zhang*, Ying Chen*, <b>Long Bai</b>, Yan Zhao, Yuxiang Sun, Yixuan Yuan, Jianhua Zhang, Hongliang Ren <br>
			<em>International Conference on Biomimetic Intelligence and Robotics & Medical Robotics Forum</em> (<i><b>ICBIR</b></i>), 2024. <br>
		</li>
			<p style="margin-top:3px">
				
			</p>	
		
		<li>
			<a href="https://arxiv.org/abs/2309.10431" target="_blank">Sample-adaptive Augmentation for Point Cloud Recognition Against Real-world Corruptions</a><br>
			Jie Wang, Lihe Ding, Tingfa Xu, Shaocong Dong, Xinli Xu, <b>Long Bai</b>, Jianan Li <br>
			<em>International Conference on Computer Vision</em> (<i><b>ICCV</b></i>), 2023. <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/Roywangj/AdaptPoint" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2307.02452" target="_blank">LLCaps: Learning to Illuminate Low-Light Capsule Endoscopy with Curved Wavelet Attention and Reverse Diffusion</a><br>
			<b>Long Bai*</b>, Tong Chen*, Yanan Wu, An Wang, Mobarakol Islam, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2023. <i><p style="color: red; display: inline;">(Oral, Top 3%)</p></i> <br>  
			<!-- <font color="red">(Oral, Top 3%)</font></br> -->
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/LLCaps" target="_blank">Code</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2307.05182" target="_blank">CAT-ViL: Co-Attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery</a><br>
			<b>Long Bai*</b>, Mobarakol Islam*, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2023. <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/CAT-ViL" target="_blank">Code</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2307.12045" target="_blank">Revisiting Distillation for Continual Learning on Visual Question Localized-Answering in Robotic Surgery</a><br>
			<b>Long Bai*</b>, Mobarakol Islam*, Hongliang Ren <br>
			<em>Medical Image Computing and Computer Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2023. <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/CS-VQLA" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2308.02845" target="_blank">Landmark Detection using Transformer Toward Robot-assisted Nasal Airway Intubation</a><br>
			Tianhang Liu, Hechen Li, <b>Long Bai†</b>, Yanan Wu, An Wang, Mobarakol Islam, Hongliang Ren <br>
			<em>International Conference on Biomimetic Intelligence and Robotics & Medical Robotics Forum</em> (<i><b>ICBIR</b></i>), 2023. <br>
			<font color="red">(Best Student Paper Award)</font></br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/ConorLTH/airway_intubation_landmarks_detection" target="_blank">Code</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2308.02869" target="_blank">Semi-supervised Learning for Segmentation of Bleeding Regions in Video Capsule Endoscopy</a><br>
			Hechen Li, Yanan Wu, <b>Long Bai†</b>, An Wang, Tong Chen, Hongliang Ren <br>
			<em>International Conference on Biomimetic Intelligence and Robotics & Medical Robotics Forum</em> (<i><b>ICBIR</b></i>), 2023. <br>
		</li>
			<p style="margin-top:3px">
				
			</p>	
		
		<li>
			<a href="https://arxiv.org/abs/2305.11692" target="_blank">Surgical-VQLA: Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery</a><br>
			<b>Long Bai*</b>, Mobarakol Islam*, Lalithkumar Seenivasan, Hongliang Ren <br>
			<em>IEEE International Conference on Robotics and Automation</em> (<i><b>ICRA</b></i>), 2023. <br>
			<font color="red">(IEEE RAS Travel Grant Award)</font></br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/longbai1006/Surgical-VQLA" target="_blank">Code</a>]
			</p>

		<li>
			<a href="https://arxiv.org/abs/2305.10955" target="_blank">Deep Reinforcement Learning-Based Control for Stomach Coverage Scanning of Wireless Capsule Endoscopy</a><br>
			Yameng Zhang*, <b>Long Bai*</b>, Li Liu, Hongliang Ren, Max Q–H Meng <br>
			<em>IEEE International Conference on Robotics and Biomimetics</em> (<i><b>ROBIO</b></i>), 2022. <br>
		</li>
			<p style="margin-top:3px">
				
			</p>

		<li>
			<a href="https://arxiv.org/abs/2108.03026" target="_blank">The Influence of Age and Gender Information on the Diagnosis of Diabetic Retinopathy: Based on Neural Networks</a><br>
			<b>Long Bai*</b>, Sihang Chen*, Mingyang Gao*, Leila Abdelrahman, Manal Al Ghamdi, Mohamed Abdel-Mottaleb <br>
			<em>Annual International Conference of the IEEE Engineering in Medicine & Biology Society</em> (<i><b>EMBC</b></i>), 2021. <br>
		</li>
			<p style="margin-top:3px">
				
			</p>
	</ul>
	
<h3>Workshop Papers</h3>
	<ul>
		<li>
			<a href="https://arxiv.org/abs/2408.04426" target="_blank">A Review of 3D Reconstruction Techniques for Deformable Tissues in Robotic Surgery</a><br>
			Mengya Xu, Ziqi Guo, An Wang, <b>Long Bai</b>, Hongliang Ren <br>
			<em>MICCAI EARTH Workshop</em>, 2024. <br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/Epsilon404/surgicalnerf" target="_blank">Code</a>]
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2404.10640" target="_blank">Adapting SAM for Surgical Instrument Tracking and Segmentation in Endoscopic Submucosal Dissection Videos</a><br>
			Jieming Yu, <b>Long Bai†</b>, Guankun Wang, An Wang, Xiaoxiao Yang, Huxin Gao, Hongliang Ren <br>
			<em>IEEE ICRA C4SR+ Workshop</em>, 2024. <br> 
			<font color="red">(Best Poster Award)</font></br> 
		</li>
			<p style="margin-top:3px">
				
			</p>
		
		<li>
			<a href="https://arxiv.org/abs/2305.11686" target="_blank">Domain Adaptive Sim-to-Real Segmentation of Oropharyngeal Organs Towards Robot-assisted Intubation</a><br>
			Guankun Wang, Tian-Ao Ren, Jiewen Lai, <b>Long Bai†</b>, Hongliang Ren <br>
			<em>IEEE ICRA Workshop on New Evolutions in Surgical Robotics</em>, 2023. <br>
			<font color="red">(Best Poster Award)</font></br> 
		</li>
			<p style="margin-top:3px">
				[<a href="https://github.com/gkw0010/EISOST-Sim2Real-Dataset-Release" target="_blank">Dataset</a>]
			</p>	
	</ul>


</tbody></table>






<h2>Professional Services</h2>

<li>	
	<b>Program Committee:</b>
	<br>
	<span style="display: block; margin-top: 0.5em;"></span>
    	Program Committee, <a href="https://earth-workshop.github.io/" target="_blank">MICCAI 2024 Workshop on Embodied AI and Robotics for HealTHcare (EARTH)</a> <br> 
    	Program Committee, <a href="https://icmi.acm.org/2023/late-breaking-results/" target="_blank">ACM ICMI 2023 Late-Breaking Results (LBR)</a> <br> 
	<!-- <p style="margin-top:3px"></p> -->		
</li>
	
	
<li>	
	<b>Regular Reviewer:</b>
	<br>
	<span style="display: block; margin-top: 0.5em;"></span>
    	MICCAI, ICRA, IROS, IPCAI, ISBI, CHI, VR, CSCW, ETRA, IUI, ICBIR<br>
	<span style="display: block; margin-top: 0.5em;"></span>
	IEEE TPAMI, IEEE TMI, IEEE TCSVT, IEEE TIM, IEEE RAL, IEEE OJIM, IEEE Sensors Journal, Information Fusion, Information Sciences, Computers in Biology and Medicine, Medical & Biological Engineering & Computing, JSCE, JMRR<br>
	<!-- <p style="margin-top:3px"></p> -->		
</li>	

	<!-- <b>Regular Reviewer:</b>
	<br>	
	<table style="border-spacing:2px">
	<tbody>
		<tr>
			<td>Conferences: </td><td>MICCAI, ICRA, IROS, IPCAI, ISBI, CHI, VR, CSCW, ETRA, IUI, ICBIR</td>	
		</tr>
		<tr>
			<td>Journals: </td><td>IEEE TPAMI, IEEE TMI, IEEE TCSVT, IEEE TIM, IEEE RAL, IEEE OJIM, IEEE Sensors Journal, Information Fusion, Information Sciences, Computers in Biology and Medicine, Medical & Biological Engineering & Computing, JSCE, JMRR</td>
		</tr>
	</tbody>
	</table>
	<br> -->
	
<h2>Invited Talks</h2>
<li>Surgical Visual Question Localized-Answering.<br>
Pre-ICRA Online,  May. 2023.
</li>
<li>Lifelong Learning: Background, Methodology, and Applications.<br>
Hong Kong University of Science and Technology (HKUST), Oct. 2022.
</li>

<h2>Teaching</h2>
	<b>Teaching Assistant:</b>
	<br>	
	<table style="border-spacing:2px">
	<tbody>
		<tr>
			<td> 2024-2025 </td><td> Spring </td><td> ELEG5757 </td><td> Intelligent Wearable Electronics </td>
		</tr>
		<tr>
			<td> 2024-2025 </td><td> Spring </td><td> ELEG3103 </td><td> Robotic Perception and Intelligence </td>
		</tr>
		<tr>
			<td> 2023-2024 </td><td> Spring </td><td> ELEG5600 </td><td> Advanced Perception for Intelligent Robotics </td>
		</tr>
		<tr>
			<td> 2023-2024 </td><td>Fall </td><td> ENGG2760 </td><td> Probability for Engineers </td>
		</tr>
		<tr>
			<td> 2022-2023 </td><td> Spring </td><td> ELEG5757 </td><td> Intelligent Wearable Electronics </td>
		</tr>
		<tr>
			<td> 2022-2023 </td><td> Fall </td><td> ENGG2760 </td><td> Probability for Engineers </td>
		</tr>
        	<tr>
			<td> 2021-2022 </td><td> Spring </td><td> ELEG3201 </td><td> Microelectronic Devices and Circuits </td>
		</tr>
		<tr>
			<td> 2021-2022 </td><td> Fall </td><td> ENGG2760 </td><td> Probability for Engineers </td>
		</tr>
	</tbody>
	</table>
	<br>	
	
	<b>Mentees:</b>
	<br>
	<table style="border-spacing:2px">
	<body>
	<tr>
		<td> Boyi Ma </td><td> Intern 2023-2024 </td><td> -> Ph.D. Student, UToronto </td>
	</tr>
	<tr>
		<td> Qiaozhi Tan </td><td> Intern 2023-2024 </td><td> -> Ph.D. Student, CityU HK </td>
	</tr>
	<tr>
		<td> Yihan Ma </td><td> Intern 2023-2024 </td><td> -> M.Sc. Student, UCL </td>
	</tr>
	<tr>
		<td> Tianhang Liu </td><td> CUHK M.Sc. 2022-2023 </td><td> -> R&D, ASTRI HK </td>
	</tr>
	<tr>
		<td> <a href="https://gkw0010.github.io/" target="_blank">Guankun Wang</a> </td><td> Intern 2022-2023 </td> <td> -> Ph.D. Student, CUHK </td>
	</tr>
	<tr>
		<td> Yuanhao Zhao </td><td> CUHK M.Sc. 2021-2022 </td><td> -> R&D, Samsung China </td>
	</tr>
	<tr>
		<td> <a href="https://scholar.google.com/citations?user=mGkM_WgAAAAJ&hl=en" target="_blank">Liangyu Wang</a> </td><td> CUHK M.Sc. 2021-2022 </td><td> -> Ph.D. Student, KAUST </td>
	</tr>
	<tr>
		<td> <a href="https://davismeee.github.io/" target="_blank">Tong Chen</a> </td><td> Intern 2021-2022 </td><td> -> M.Phil.-Ph.D. Student, USYD </td>
	</tr>
	</tbody>
	</table>
<br>


<div id="footer">
	<div id="footer-text"></div>
</div>
	<p><center>
	<div id="clustrmaps-widget" style="width:10%">
		<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=QW1b-GJYj119mme9wSJ8T-_BmnDNjhQcaK_IFmm8y1o"></script>
	</div>
		
	<br>
        &copy; Long Bai | Last updated: Sept 2024
     
      </center></p>


</div>
</body></html>
